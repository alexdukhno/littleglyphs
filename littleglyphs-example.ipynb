{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the project library for glyph generation, classification, plotting, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import littleglyphs as lilg\n",
    "import littleglyphs.plotting as lilgplt\n",
    "import littleglyphs.classification as lilgcls\n",
    "import littleglyphs.examples as lilgex\n",
    "\n",
    "import importlib\n",
    "importlib.reload(lilg)\n",
    "importlib.reload(lilgplt)\n",
    "importlib.reload(lilgcls)\n",
    "importlib.reload(lilgex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import prerequisite libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import skimage\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "random_seed = 456\n",
    "\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a glyph _alphabet_ (an array of glyphs each belonging to a unique _category_). From it, making a set of glyphs with slightly different strokes (glyph _permutations_), produce images, then use a set of transformations (_distortions_) on those images to produce glyph _variations_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_glyphs_in_alphabet = 15\n",
    "\n",
    "N_bezier_features = 0\n",
    "N_line_features = 0\n",
    "N_ellipse_features = 0\n",
    "N_multipoint_line_features = 0\n",
    "multipoint_line_feature_N_points = 3\n",
    "N_multipoint_bezier_features = 1\n",
    "multipoint_bezier_feature_N_points = 3\n",
    "\n",
    "\n",
    "N_glyph_permutations = 20\n",
    "permutation_strength = 0.05\n",
    "\n",
    "imgsize = 16\n",
    "\n",
    "N_glyph_raster_distortions = 30\n",
    "rotat_distort_max = np.pi / 8\n",
    "shear_distort_max = np.pi / 8\n",
    "scale_distort_max = 0.25\n",
    "\n",
    "blur_factor = 1\n",
    "\n",
    "N_variations_per_glyph = N_glyph_permutations*N_glyph_raster_distortions\n",
    "\n",
    "time_start = time.time()\n",
    "print('Generating glyph alphabet and glyph variations... ', end='')\n",
    "\n",
    "def makeRandomGlyph(category):\n",
    "    glyph = lilg.Glyph(\n",
    "        [lilg.FeatureBezierCurve() for count in range(0,N_bezier_features)]+\n",
    "        [lilg.FeatureLineSegment() for count in range(0,N_line_features)]+\n",
    "        [lilg.FeatureEllipse() for count in range(0,N_ellipse_features)]+\n",
    "        [lilg.FeatureMultiPointLineSegment(multipoint_line_feature_N_points) for count in range(0,N_multipoint_line_features)]+\n",
    "        [lilg.FeatureMultiPointBezierCurve(multipoint_bezier_feature_N_points) for count in range(0,N_multipoint_bezier_features)]\n",
    "    )\n",
    "    glyph.set_category(category)\n",
    "    glyph.randomize_all_features()\n",
    "    return glyph\n",
    "\n",
    "glyphs = []\n",
    "glyph_categories = list(range(0,N_glyphs_in_alphabet))\n",
    "\n",
    "#for category in glyph_categories:\n",
    "#    glyph = makeRandomGlyph(category)\n",
    "#    glyphs.append(glyph)\n",
    "    \n",
    "starter_glyph = makeRandomGlyph(0)    \n",
    "for category in glyph_categories:\n",
    "    glyph = starter_glyph.permuted(permutation_strength)\n",
    "    glyph.set_category(category)\n",
    "    glyphs.append(glyph)\n",
    "\n",
    "glyph_alphabet = lilg.GlyphList(glyphs)\n",
    "\n",
    "#glyph_alphabet = lilg.examples.MNISTlike_glyph_alphabet()\n",
    "#N_glyphs_in_alphabet = len(glyph_alphabet)\n",
    "\n",
    "glyph_permuted_alphabet = glyph_alphabet.permuted(permutation_strength, N_glyph_permutations)\n",
    "\n",
    "glyph_rasters = glyph_permuted_alphabet.render(\n",
    "    (imgsize,imgsize), \n",
    "    blur_factor=blur_factor,randomize_blur=True,random_blur_extent=2\n",
    ")\n",
    "distorter = lilg.SequentialDistorter(\n",
    "    [\n",
    "        lilg.DistortionRandomAffine(\n",
    "            rotat_distort_max = rotat_distort_max, \n",
    "            shear_distort_max = shear_distort_max,\n",
    "            scale_distort_max = scale_distort_max\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "glyph_rasters = glyph_rasters.distorted(distorter, N_glyph_raster_distortions)\n",
    "\n",
    "\n",
    "time_end = time.time()\n",
    "print('done in '+'{0:.3f}'.format(time_end-time_start)+' sec '+\n",
    "     '('+'{0:.3f}'.format((time_end-time_start)/N_glyphs_in_alphabet)+' sec per glyph).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the glyphs and show some examples of glyph rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ground truth glyphs:')\n",
    "fig, axs = lilgplt.visualize_glyph_list(\n",
    "    glyph_alphabet,\n",
    "    N_glyphs_to_show = N_glyphs_in_alphabet, \n",
    "    imgsize=128, \n",
    "    blur_factor=0.5*16,\n",
    "    figsize=(12,6)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Examples of glyph images:')\n",
    "N_images_to_show = 50\n",
    "\n",
    "random_indices = np.arange(len(glyph_rasters))\n",
    "np.random.shuffle(random_indices)\n",
    "vis_imgs = glyph_rasters[random_indices[0:N_images_to_show]]\n",
    "vis_categories = glyph_rasters.categories[random_indices[0:N_images_to_show]]\n",
    "\n",
    "_ = lilgplt.visualize_img_array(vis_imgs,vis_categories,N_images_to_show,figsize=(10,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize the data using a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a one-hot encoded category correspondence array for the glyph variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_classes, inverse_category_class_indices = np.unique(glyph_rasters.categories, return_inverse=True)\n",
    "N_classes = len(category_classes)\n",
    "\n",
    "X = glyph_rasters.rasters\n",
    "Y = keras.utils.to_categorical(glyph_rasters.categories, num_classes=N_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our data ready to be fed to the categorizer. Split it into training, cross-validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_cv, Y_cv, X_test, Y_test = lilgcls.split_data_for_learning(\n",
    "    X, Y, \n",
    "    crossval_proportion = 0.2, \n",
    "    test_proportion = 0.2, \n",
    "    random_seed=random_seed\n",
    ")\n",
    "    \n",
    "print(\"X_train matrix shape: \"+str(X_train.shape)+\"; Y_train matrix shape: \"+str(Y_train.shape))\n",
    "print(\"X_test  matrix shape: \"+str(X_test.shape )+\"; Y_test  matrix shape: \"+str(Y_test.shape ))\n",
    "print(\"X_cv    matrix shape: \"+str(X_cv.shape   )+\"; Y_cv    matrix shape: \"+str(Y_cv.shape   ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = lilgcls.make_CNN_model(imgsize, N_classes, complexity = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our model. Transform the data into a format that can be fed to it, and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv = lilgcls.prep_data_for_CNN_model(X_train, imgsize)\n",
    "X_cv_conv = lilgcls.prep_data_for_CNN_model(X_cv, imgsize)\n",
    "\n",
    "N_epochs = 10\n",
    "\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "#checkpoint_filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]\n",
    "\n",
    "h = model.fit(\n",
    "    X_train_conv, Y_train, \n",
    "    epochs=N_epochs, batch_size=N_classes*10, \n",
    "    verbose=2,\n",
    "    #callbacks=callbacks_list, \n",
    "    validation_data=(X_cv_conv,Y_cv)\n",
    ")\n",
    "\n",
    "#from IPython.display import Audio\n",
    "#Audio('./bell.ogg',autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the evolution of training/cross-validation losses and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurs = h.history['acc']\n",
    "val_accurs = h.history['val_acc']\n",
    "losses = h.history['loss']\n",
    "val_losses = h.history['val_loss']\n",
    "epoch_numbers = h.epoch\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "plt.plot(epoch_numbers, losses, label='training loss per epoch')\n",
    "plt.plot(epoch_numbers, val_losses, label='cross-val. loss per epoch')\n",
    "plt.plot(epoch_numbers, accurs, label='training accuracy per epoch')\n",
    "plt.plot(epoch_numbers, val_accurs, label='cross-val. accuracy per epoch')\n",
    "ax.set_ylim([0,None])\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "X_test_conv = lilgcls.prep_data_for_CNN_model(X_test,imgsize)\n",
    "loss_and_metrics = model.evaluate(X_test_conv, Y_test, batch_size=128)\n",
    "print('Loss on test set: ~'+'{0:.2f}'.format(loss_and_metrics[0]))\n",
    "print('Accuracy on test set: ~'+'{0:.0f}'.format(loss_and_metrics[1]*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model's predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = model.predict(X_test_conv, batch_size=128)\n",
    "Y_predicted_class = np.argmax(Y_predicted, axis=1)\n",
    "Y_predicted_probability = np.max(Y_predicted, axis=1)\n",
    "Y_test_class = np.argmax(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the examples of test data and predictions on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_images_to_show = 50\n",
    "\n",
    "vis_imgs = X_test[:N_images_to_show]\n",
    "vis_categories = Y_predicted_class[:N_images_to_show]\n",
    "vis_probabilities = Y_predicted_probability[:N_images_to_show]\n",
    "\n",
    "_ = lilgplt.visualize_img_array(vis_imgs,vis_categories,N_images_to_show,\n",
    "                             show_probabilities=True,probabilities=vis_probabilities,\n",
    "                             cmap = 'hot_r', figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the ambiguous glyphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate probabilistic confusion entropy matrix. \n",
    "\n",
    "The matrix is basically like a regular confusion matrix, but instead of discretely treating the highest output of the classifier as the output class, it smoothly treats all outputs of the classifier as \"surety\" of the classifier in each class. This uncovers information about the cases where the classifier works, but is not very sure in its answers.\n",
    "\n",
    "Each row corresponds to the \"true\" class. Each column corresponds to the \"surety\" of the classifier in its output for the column. So, for instance, an element [4,2] corresponds to the average degree of surety with which the classifier says \"it belongs to class 2\" when it sees an element that in reality belongs to class 4.\n",
    "Similarly to the case of a regular confusion matrix, a good classifier will have high values of diagonal elements and low values of all other elements.\n",
    "\n",
    "( Based on doi:10.3390/e15114969 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_conf_ent_matrix = lilgcls.prob_conf_ent_matrix(Y_test,Y_predicted,N_classes)\n",
    "\n",
    "worst_class_index = np.diagonal(prob_conf_ent_matrix).argmin()\n",
    "best_class_index =  np.diagonal(prob_conf_ent_matrix).argmax()\n",
    "\n",
    "print('Probabilistic confusion entropy matrix:')\n",
    "#print(np.around(prob_conf_ent_matrix,decimals=3))\n",
    "plt.imshow(prob_conf_ent_matrix, vmin=0, vmax=1, cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print('Class with worst performance: '+str(worst_class_index))\n",
    "print('Class with best performance:  '+str(best_class_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the worst confusion case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_conf_ent_matrix_nodiag = prob_conf_ent_matrix.copy()\n",
    "np.fill_diagonal(prob_conf_ent_matrix_nodiag,0)\n",
    "\n",
    "worst_confusion_index = np.unravel_index(\n",
    "    np.argmax(prob_conf_ent_matrix_nodiag, axis=None), \n",
    "    prob_conf_ent_matrix_nodiag.shape\n",
    ")\n",
    "print('Most confused pair: class '\n",
    "      +str(worst_confusion_index[0])\n",
    "      +' is being mistaken for class '\n",
    "      +str(worst_confusion_index[1])\n",
    "      +' with probability '\n",
    "      +str(np.around(prob_conf_ent_matrix_nodiag[worst_confusion_index],decimals=3))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise examples of the glyphs corresponding to the worst encountered confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Actual distribution of classes for test data:')\n",
    "print(np.bincount(Y_test_class))\n",
    "print('Distribution of classes for test data as predicted by the classifier:')\n",
    "print(np.bincount(Y_predicted_class))\n",
    "\n",
    "N_images_to_show = 18\n",
    "\n",
    "print('Examples of class '+str(worst_confusion_index[0])+':')\n",
    "vis_indices = np.where(Y_test_class == worst_confusion_index[0])[0]\n",
    "vis_indices = vis_indices[:N_images_to_show]\n",
    "vis_imgs = X_test[vis_indices]\n",
    "vis_categories = Y_predicted_class[vis_indices]\n",
    "vis_probabilities = Y_predicted_probability[vis_indices]\n",
    "\n",
    "_ = lilgplt.visualize_img_array(vis_imgs,vis_categories,N_images_to_show,\n",
    "                             show_probabilities=True,probabilities=vis_probabilities,\n",
    "                             cmap='hot_r', figsize=(6,3)                            \n",
    "                            )\n",
    "plt.show()\n",
    "\n",
    "print('Examples of class '+str(worst_confusion_index[1])+':')\n",
    "vis_indices = np.where(Y_test_class == worst_confusion_index[1])[0]\n",
    "vis_imgs = X_test[vis_indices]\n",
    "vis_categories = Y_predicted_class[vis_indices]\n",
    "vis_probabilities = Y_predicted_probability[vis_indices]\n",
    "\n",
    "_ = lilgplt.visualize_img_array(vis_imgs,vis_categories,N_images_to_show,                             \n",
    "                             show_probabilities=True,probabilities=vis_probabilities,\n",
    "                             cmap='hot_r', figsize=(6,3)\n",
    "                            )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly generate glyphs until spotting a glyph that has a lot of _ambiguity for the current classifier_. An _ambiguous_ glyph is defined as one with which the classifier has trouble assigning it to any of the classes.\n",
    "\n",
    "Note that selecting for ambiguity __does not necessarily__ select a glyph that is the most _dissimilar_ to the glyphs encountered by the classifier. For instance, a glyph that combines some elements of all glyphs in current alphabet would likely be quite ambiguous. So could be a glyph that doesn't look like any of the glyphs in current alphabet.\n",
    "\n",
    "To define a metric for ambiguity, we can use the euclidean square distance of the probability matrix diagonal to the diagonal for the ideal ambiguous symbol. E.g. if we have two different symbols with an ideal classifier, the probability matrix would be: \n",
    "``` \n",
    "1 0\n",
    "0 1\n",
    "```\n",
    "while two identical symbols (or a purely random classifier) would have a matrix of\n",
    "```\n",
    "0.5 0.5\n",
    "0.5 0.5\n",
    "```\n",
    "\n",
    "So for a glyph that is classified as ```[0.8 0.2]``` the distance from ideal ambiguity would be (0.8-0.5)^2 + (0.2-0.5)^2 = ```0.18```, while for a glyph that is classified as ```[0.6 0.4]``` the distance would be (0.6-0.5)^2 + (0.4-0.5)^2 = ```0.02```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ambiguity = N_classes # an impossibly high value for ambiguity distance\n",
    "ideal_ambiguity_probability = np.ones(N_classes) * (1/N_classes)\n",
    "worst_glyph_ambiguity = np.sum((prob_conf_ent_matrix[worst_class_index] - ideal_ambiguity_probability)**2)\n",
    "\n",
    "new_candidate_glyph_ambiguity_threshold = worst_glyph_ambiguity / 10\n",
    "new_candidate_glyph_ambiguity_maxiter = 20\n",
    "\n",
    "print(\n",
    "    'Worst glyph\\'s distance from ideal ambiguity: '+\n",
    "    str(np.around(worst_glyph_ambiguity, decimals=3))\n",
    ")\n",
    "\n",
    "print(\n",
    "    'Generating new glyph to replace the glyph with worst performance (target ambiguity distance: '+\n",
    "    str(np.around(new_candidate_glyph_ambiguity_threshold,decimals=3))+\n",
    "    '):'\n",
    ")\n",
    "\n",
    "i = 0\n",
    "while (\n",
    "    (i < new_candidate_glyph_ambiguity_maxiter) and \n",
    "    (best_ambiguity > new_candidate_glyph_ambiguity_threshold)\n",
    "):\n",
    "    new_candidate_glyph = makeRandomGlyph(worst_class_index)\n",
    "    \n",
    "    new_glyph_perm_list = lilg.GlyphList([new_candidate_glyph])\n",
    "    new_glyph_perm_list = new_glyph_perm_list.permuted(permutation_strength, N_glyph_permutations)\n",
    "\n",
    "    new_glyph_rasters = new_glyph_perm_list.render(\n",
    "        (imgsize,imgsize), \n",
    "        blur_factor=blur_factor,randomize_blur=True,random_blur_extent=2\n",
    "    )\n",
    "    \n",
    "    new_glyph_rasters = new_glyph_rasters.distorted(distorter, N_glyph_raster_distortions)\n",
    "    \n",
    "    X_new = new_glyph_rasters.rasters\n",
    "    X_new_conv = lilgcls.prep_data_for_CNN_model(X_new,imgsize)\n",
    "    Y_new_predicted = model.predict(X_new_conv, batch_size=128)\n",
    "\n",
    "    Y_new_mean_class_probability = Y_new_predicted.mean(axis=0)\n",
    "    #print('Candidate for new glyph - average classification:')\n",
    "    #print(np.around(Y_new_mean_class_probability, decimals=3))\n",
    "    #print('Candidate for new glyph - square distance from ideal ambiguity:')    \n",
    "    distance_from_ideal_ambiguity = (Y_new_mean_class_probability - ideal_ambiguity_probability)**2\n",
    "    #print(np.around(distance_from_ideal_ambiguity, decimals=3))\n",
    "    total_distance_from_ideal_ambiguity = np.sum(distance_from_ideal_ambiguity)\n",
    "    #print('Total distance from ideal ambiguity: '+str(np.around(total_distance_from_ideal_ambiguity, decimals=3)))\n",
    "    #print()\n",
    "    \n",
    "    if best_ambiguity>total_distance_from_ideal_ambiguity:\n",
    "        best_ambiguity = total_distance_from_ideal_ambiguity\n",
    "        best_new_candidate_glyph = copy.deepcopy(new_candidate_glyph)\n",
    "        best_new_glyph_rasters = copy.deepcopy(new_glyph_rasters)\n",
    "        \n",
    "    print(\n",
    "        '\\rIteration ' + str(i) + ': '+\n",
    "        'current distance from ideal ambiguity: '+\n",
    "        str(np.around(total_distance_from_ideal_ambiguity, decimals=3))+\n",
    "        '; best: '+\n",
    "        str(np.around(best_ambiguity, decimals=3)),\n",
    "        end=''\n",
    "    )\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "\n",
    "new_candidate_glyph = best_new_candidate_glyph\n",
    "new_glyph_rasters = best_new_glyph_rasters\n",
    "print()\n",
    "print(\n",
    "    'Best candidate distance from ideal ambiguity: '+str(np.around(best_ambiguity, decimals=3))+\n",
    "    ', found in '+str(i)+' iterations (max '+str(new_candidate_glyph_ambiguity_maxiter)+' iterations).'\n",
    ")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Examples of new glyph images:')\n",
    "N_images_to_show = 50\n",
    "\n",
    "random_indices = np.arange(len(new_glyph_rasters))\n",
    "np.random.shuffle(random_indices)\n",
    "vis_imgs = new_glyph_rasters[random_indices[0:N_images_to_show]]\n",
    "vis_categories = new_glyph_rasters.categories[random_indices[0:N_images_to_show]]\n",
    "\n",
    "_ = lilgplt.visualize_img_array(vis_imgs,vis_categories,N_images_to_show,figsize=(10,4))\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('./results/test.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporate the new glyph in place of the old one. Generate a new set of rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glyph_alphabet.remove_glyph_category(worst_class_index)\n",
    "glyph_alphabet.add_glyph(new_candidate_glyph)\n",
    "glyph_alphabet.sort_by_category()\n",
    "\n",
    "time_start = time.time()\n",
    "print('Generating new glyph variations... ', end='')\n",
    "\n",
    "glyph_permuted_alphabet = glyph_alphabet.permuted(permutation_strength, N_glyph_permutations)\n",
    "\n",
    "glyph_rasters = glyph_permuted_alphabet.render(\n",
    "    (imgsize,imgsize), \n",
    "    blur_factor=blur_factor,randomize_blur=True,random_blur_extent=2\n",
    ")\n",
    "glyph_rasters = glyph_rasters.distorted(distorter, N_glyph_raster_distortions)\n",
    "   \n",
    "time_end = time.time()\n",
    "print('done in '+'{0:.3f}'.format(time_end-time_start)+' sec '+\n",
    "     '('+'{0:.3f}'.format((time_end-time_start)/N_glyphs_in_alphabet)+' sec per glyph).')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_for_tensorflow",
   "language": "python",
   "name": "py36_for_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
